# Anatomia de Uma Rede Neural | SimpleNet

## 1. Introdu√ß√£o üìñ

<p style='text-align: justify;'>Neste projeto, embarcamos em uma explora√ß√£o detalhada para desvendar os intricados detalhes da constru√ß√£o de modelos de Deep Learning. O objetivo principal √© fornecer um entendimento abrangente das etapas fundamentais envolvidas na constru√ß√£o desses modelos, utilizando as poderosas ferramentas PyTorch e PyTorch Lightning.</p>

<p style='text-align: justify;'>O <a href="https://pytorch.org/get-started/pytorch-2.0/" target="_blank">PyTorch</a> √© uma biblioteca de aprendizado profundo de c√≥digo aberto que oferece a flexibilidade e a velocidade necess√°rias na pesquisa de aprendizado profundo. Ele suporta opera√ß√µes de tensor com acelera√ß√£o de GPU, fornece uma plataforma de aprendizado profundo que oferece versatilidade e velocidade, e se integra perfeitamente ao ecossistema Python.</p>

<p style='text-align: justify;'>Por outro lado, o <a href="https://lightning.ai/docs/pytorch/stable/" target="_blank">PyTorch Lightning</a> √© uma estrutura leve que organiza o c√≥digo PyTorch. Ele permite que os pesquisadores se concentrem nas partes inovadoras de seus projetos, eliminando a necessidade de escrever c√≥digo repetitivo. Constru√≠do sobre o PyTorch, o PyTorch Lightning permite que voc√™ escale seus modelos sem a necessidade de reescrever seu c√≥digo.</p>


<p style='text-align: justify;'>Este caderno vai al√©m de um simples tutorial; √© uma explora√ß√£o pr√°tica do mundo fascinante do Deep Learning. Este projeto √© fruto da minha forma√ß√£o como Engenheiro de Intelig√™ncia Artificial na <a href="https://www.datascienceacademy.com.br/start" target="_blank">Data Science Academy</a>. Com este caderno, esperamos n√£o apenas ensinar, mas tamb√©m inspirar voc√™ a explorar ainda mais as possibilidades do Deep Learning.</p>

## 2. Configura√ß√£o ‚öôÔ∏è

### 2.1 Carga de Pacotes Python

O caderno criado para este projeto utiliza v√°rias bibliotecas Python, cada uma com um prop√≥sito espec√≠fico, algumas das principais s√£o:

<div style="background-color: #f0f0f0; padding: 10px; border-radius: 10px;">

1. **os**: `Interage com o sistema operacional, permitindo a manipula√ß√£o de arquivos e diret√≥rios.`
2. **warnings**: `Emite mensagens de aviso ao usu√°rio.`
4. **torch e lightning (pl)**: `PyTorch √© usado para aprendizado profundo e PyTorch Lightning organiza o c√≥digo PyTorch.`

</div>

<center><div style="display: flex; justify-content: center; align-items: center;">
    <img src="imagens/torch.jpeg" alt="torch" style="width:180px; margin: 15px;"> 
    <img src="imagens/lightning.png" alt="lightning" style="width:190px; margin: 15px;">
</div></center>

## 3. Prepara√ß√£o e Carregamento dos Dados üíΩ

### 3.1 Gerando Dados para o Problema XOR (OU Exclusivo)

<center><img src="imagens/xor.png" width=50%;></center>

<p style='text-align: justify;'>Este projeto prepara um conjunto de dados para treinar um modelo de rede neural para resolver o problema XOR. O problema XOR √© um problema cl√°ssico em redes neurais que n√£o pode ser resolvido por uma √∫nica camada de perceptron, pois os dados do XOR n√£o s√£o linearmente separ√°veis.</p>

A cria√ß√£o dos dados para treinamento consiste em:

<div style="background-color: #FAF0E6; padding: 10px; border-radius: 10px;">

1. **Dados de entrada e sa√≠da**: As vari√°veis `dados_entrada` e `dados_saida` cont√™m os quatro poss√≠veis pares de entradas bin√°rias e suas respectivas sa√≠das para a opera√ß√£o XOR. Por exemplo, [0, 0] produz 0 e [0, 1] produz 1.

2. **Dataset final**: A vari√°vel `dados_final` combina os dados de entrada e sa√≠da em uma √∫nica lista de tuplas. Cada tupla cont√©m um par de entrada e a sa√≠da correspondente.

3. **DataLoader**: A vari√°vel `loader_treinamento` √© um DataLoader do PyTorch, que √© uma ferramenta para carregar os dados em lotes durante o treinamento de uma rede neural. Neste caso, o tamanho do lote √© definido como 1, o que significa que cada lote conter√° apenas um par de entrada-sa√≠da.
    
</div>

## 4. SimpleNet: Uma Vis√£o Geral üß†

A `SimpleNet` √© uma classe que implementa uma rede neural simples usando PyTorch Lightning. A rede consiste em uma camada de entrada, uma camada de sa√≠da e uma fun√ß√£o de ativa√ß√£o sigm√≥ide.

No m√©todo `__init__`, a camada de entrada, a camada de sa√≠da, a fun√ß√£o de ativa√ß√£o sigm√≥ide e a fun√ß√£o de perda s√£o inicializadas. A camada de entrada √© uma camada linear que recebe 2 entradas e produz 4 sa√≠das. A camada de sa√≠da √© outra camada linear que recebe 4 entradas (do output da camada de entrada) e produz 1 sa√≠da. A fun√ß√£o de ativa√ß√£o sigm√≥ide √© usada para adicionar n√£o-linearidade ao modelo. A fun√ß√£o de perda usada √© a perda quadr√°tica m√©dia (MSE).

O m√©todo `forward` realiza a passagem para frente na rede neural. A entrada passa pela camada de entrada, depois pela fun√ß√£o de ativa√ß√£o sigm√≥ide e finalmente pela camada de sa√≠da.

O m√©todo `configure_optimizers` configura o otimizador para a rede neural. Ele usa o otimizador Adam com uma taxa de aprendizado de 0.01.

O m√©todo `training_step` realiza uma etapa de treinamento na rede neural. A perda √© calculada comparando as sa√≠das da rede com as sa√≠das reais usando a fun√ß√£o de perda definida no construtor.

---

<center><img src="imagens/simplenet.png" width=40%;></center>

### 4.1 Fun√ß√£o de Custo (MSE)

A fun√ß√£o de custo **Mean Squared Error** (MSE), ou Erro Quadr√°tico M√©dio em portugu√™s, √© uma das fun√ß√µes de perda mais utilizadas para problemas de regress√£o. Ela calcula a m√©dia dos quadrados das diferen√ßas entre os valores previstos e os valores reais.

Aqui est√° a f√≥rmula matem√°tica para o MSE:

$$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

Onde:

- $n$ √© o n√∫mero total de exemplos no conjunto de dados
- $y_i$ √© o valor real do i-√©simo exemplo
- $\hat{y}_i$ √© o valor previsto do i-√©simo exemplo


O objetivo durante o treinamento de um modelo de aprendizado de m√°quina √© minimizar essa fun√ß√£o de perda. Isso significa que queremos que nossas previs√µes ($\hat{y}_i$) estejam o mais pr√≥ximo poss√≠vel dos valores reais ($y_i$). Quanto menor o MSE, melhor nosso modelo √© capaz de realizar previs√µes precisas.

### 4.2 Algoritmo Adam (Adaptive Moment Estimation)

O algoritmo Adam (Adaptive Moment Estimation) √© um m√©todo de otimiza√ß√£o que pode ser usado em vez dos procedimentos cl√°ssicos de descida de gradiente estoc√°stico para atualizar os pesos da rede de forma iterativa com base nos dados de treinamento.

Adam √© uma combina√ß√£o dos m√©todos AdaGrad e RMSProp, que s√£o outros algoritmos de otimiza√ß√£o. Ele calcula taxas de aprendizado adaptativas para diferentes par√¢metros. Em outras palavras, ele computa m√©dias m√≥veis tanto do gradiente quanto do quadrado do gradiente, e essas m√©dias s√£o usadas para dimensionar a taxa de aprendizado.

Aqui est√£o as f√≥rmulas matem√°ticas para o Adam:

$$m_t = \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t$$
$$v_t = \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot g_t^2$$
$$\hat{m}_t = \frac{m_t}{1 - \beta_1^t}$$
$$\hat{v}_t = \frac{v_t}{1 - \beta_2^t}$$
$$\theta_t = \theta_{t-1} - \alpha \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}$$

Onde:

- $m_t$ e $v_t$ s√£o estimativas do primeiro momento (a m√©dia) e do segundo momento (a vari√¢ncia n√£o centralizada) do gradiente, respectivamente.
- $\beta_1$ e $\beta_2$ s√£o os fatores de decaimento para essas estimativas.
- $g_t$ √© o gradiente no tempo $t$.
- $\hat{m}_t$ e $\hat{v}_t$ s√£o vers√µes corrigidas por vi√©s de $m_t$ e $v_t$.
- $\alpha$ √© a taxa de aprendizado.
- $\epsilon$ √© um termo de suaviza√ß√£o para evitar a divis√£o por zero.
- $\theta_t$ √© o par√¢metro atualizado no tempo $t$.

O algoritmo Adam √© bastante eficaz e requer pouca configura√ß√£o de mem√≥ria, sendo uma escolha popular para redes neurais profundas.

### 4.3 Retropropaga√ß√£o no SimpleNet

O processo de retropropaga√ß√£o (Backward Propagation) √© um algoritmo usado em redes neurais para calcular o gradiente da fun√ß√£o de perda em rela√ß√£o aos pesos da rede. Ele √© chamado de "backpropagation" porque o c√°lculo do gradiente √© feito de tr√°s para frente, come√ßando da fun√ß√£o de perda e indo at√© as camadas de entrada.

Aqui est√° uma descri√ß√£o detalhada do processo de retropropaga√ß√£o na sua rede SimpleNet:

1. **C√°lculo do Erro**: Primeiro, calculamos o erro da previs√£o usando a fun√ß√£o de custo MSE. Para um √∫nico exemplo, o erro √© dado por:

    $$E = \frac{1}{2}(y - \hat{y})^2$$

    onde $y$ √© o valor real e $\hat{y}$ √© o valor previsto pela rede.

2. **Gradiente na Camada de Sa√≠da**: O pr√≥ximo passo √© calcular o gradiente do erro em rela√ß√£o aos pesos da camada de sa√≠da. Usando a regra da cadeia, temos:

    $$\frac{\partial E}{\partial w_{out}} = \frac{\partial E}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial w_{out}}$$

    Onde $w_{out}$ s√£o os pesos da camada de sa√≠da. Calculamos cada parte separadamente:

    $$\frac{\partial E}{\partial \hat{y}} = -(y - \hat{y})$$

    $$\frac{\partial \hat{y}}{\partial w_{out}} = \hat{y}(1 - \hat{y}) \cdot h_{out}$$

    Onde $h_{out}$ √© a sa√≠da da camada oculta. Portanto, o gradiente na camada de sa√≠da √©:

    $$\frac{\partial E}{\partial w_{out}} = -(y - \hat{y}) \cdot \hat{y}(1 - \hat{y}) \cdot h_{out}$$

3. **Gradiente na Camada de Entrada**: Da mesma forma, podemos calcular o gradiente do erro em rela√ß√£o aos pesos da camada de entrada:

    $$\frac{\partial E}{\partial w_{in}} = \frac{\partial E}{\partial h_{out}} \cdot \frac{\partial h_{out}}{\partial w_{in}}$$

    Onde $w_{in}$ s√£o os pesos da camada de entrada. Novamente, calculamos cada parte separadamente:

    $$\frac{\partial E}{\partial h_{out}} = \frac{\partial E}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial h_{out}} = -(y - \hat{y}) \cdot \hat{y}(1 - \hat{y})$$

    $$\frac{\partial h_{out}}{\partial w_{in}} = h_{out}(1 - h_{out}) \cdot x$$

    Onde $x$ √© a entrada para a rede. Portanto, o gradiente na camada de entrada √©:

    $$\frac{\partial E}{\partial w_{in}} = -(y - \hat{y}) \cdot \hat{y}(1 - \hat{y}) \cdot h_{out}(1 - h_{out}) \cdot x$$

4. **Atualiza√ß√£o dos Pesos**: Finalmente, usamos o algoritmo Adam para atualizar os pesos em ambas as camadas. O Adam ajusta a taxa de aprendizado para cada peso individualmente, com base nas estimativas do primeiro e segundo momentos do gradiente.

## 5. Avalia√ß√£o e Conclus√£o üéØ

Os resultados obtidos demonstram que a rede neural `SimpleNet` foi capaz de aprender com sucesso a fun√ß√£o XOR. As previs√µes do modelo para as quatro combina√ß√µes poss√≠veis de entradas bin√°rias correspondem exatamente aos valores reais. Isso indica que a rede foi capaz de capturar a rela√ß√£o n√£o linear entre as entradas e a sa√≠da, demonstrando a efic√°cia do uso de redes neurais multicamadas e do algoritmo de otimiza√ß√£o Adam para resolver problemas complexos de classifica√ß√£o bin√°ria. Esses resultados promissores sugerem que abordagens semelhantes podem ser aplicadas com sucesso a problemas mais complexos e desafiadores em aprendizado de m√°quina e intelig√™ncia artificial.